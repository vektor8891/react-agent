{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1ff7899",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2265b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import HarmBlockThreshold, HarmCategory\n",
    "\n",
    "safety_settings = {\n",
    "    HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7d31b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "    # temperature (float): The sampling temperature controls the degree of\n",
    "    # randomness in token selection.\n",
    "    \"temperature\": 0.28,\n",
    "    # max_output_tokens (int): The token limit determines the maximum amount of\n",
    "    # text output from one prompt.\n",
    "    \"max_output_tokens\": 1000,\n",
    "    # top_p (float): Tokens are selected from most probable to least until\n",
    "    # the sum of their probabilities equals the top-p value.\n",
    "    \"top_p\": 0.95,\n",
    "    # top_k (int): The next token is selected from among the top-k most\n",
    "    # probable tokens. This is not supported by all model versions. See\n",
    "    # https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/image-understanding#valid_parameter_values\n",
    "    # for details.\n",
    "    \"top_k\": None,\n",
    "    # safety_settings (Dict[HarmCategory, HarmBlockThreshold]): The safety\n",
    "    # settings to use for generating content.\n",
    "    # (you must create your safety settings using the previous step first).\n",
    "    \"safety_settings\": safety_settings,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "220b2901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai import agent_engines\n",
    "\n",
    "agent = agent_engines.LanggraphAgent(\n",
    "    model=model,                # Required.\n",
    "    model_kwargs=model_kwargs,  # Optional.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05640bbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is the exchange rate from US dollars to SEK today?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/react-agent-qhG6BnnD-py3.12/lib/python3.12/site-packages/vertexai/agent_engines/templates/langgraph.py:565\u001b[39m, in \u001b[36mLanggraphAgent.query\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mquery\u001b[39m(\n\u001b[32m    545\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    546\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    549\u001b[39m     **kwargs: Any,\n\u001b[32m    550\u001b[39m ) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    551\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Queries the Agent with the given input and config.\u001b[39;00m\n\u001b[32m    552\u001b[39m \n\u001b[32m    553\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    563\u001b[39m \u001b[33;03m        The output of querying the Agent with the given input and config.\u001b[39;00m\n\u001b[32m    564\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dump \u001b[38;5;28;01mas\u001b[39;00m langchain_load_dump\n\u001b[32m    567\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    568\u001b[39m         \u001b[38;5;28minput\u001b[39m = {\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28minput\u001b[39m}\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "response = agent.query(input={\"messages\": [\n",
    "    (\"user\", \"What is the exchange rate from US dollars to SEK today?\"),\n",
    "]})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a3a674",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "react-agent-qhG6BnnD-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
